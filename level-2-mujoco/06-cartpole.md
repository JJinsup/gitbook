---
description: >-
  ë¡œë´‡ ì œì–´ ì´ë¡ ì˜ ê°€ì¥ ê³ ì „ì ì´ê³  ì¤‘ìš”í•œ ì˜ˆì œì¸ Cart-Pole (Inverted Pendulum, ì—­ì§„ì) ì‹œìŠ¤í…œì„ ê°•í™”í•™ìŠµìœ¼ë¡œ
  ë‹¤ë£¹ë‹ˆë‹¤.
layout:
  width: default
  title:
    visible: true
  description:
    visible: true
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
  metadata:
    visible: true
metaLinks:
  alternates:
    - https://app.gitbook.com/s/yE16Xb3IemPxJWydtPOj/basics/interactive-blocks
---

# ğŸ¤– \[6] MuJoCo: Cart-Pole ì œì–´ì™€ ê°•í™”í•™ìŠµ

### ğŸ¯ ì‹¤ìŠµ ëª©í‘œ

ìš°ë¦¬ëŠ” ë³µì¡í•œ ìˆ˜í•™ì  ì œì–´ ì´ë¡ (LQR ë“±)ì„ ì§ì ‘ í‘¸ëŠ” ëŒ€ì‹ , **MuJoCo ì‹œë®¬ë ˆì´ì…˜**ê³¼ **PPO ê°•í™”í•™ìŠµ**ì„ ê²°í•©í•˜ì—¬ ë¡œë´‡ì´ ìŠ¤ìŠ¤ë¡œ ê· í˜• ì¡ëŠ” ë²•ì„ í•™ìŠµí•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤.

1. **ë™ì—­í•™ ëª¨ë¸ë§ (Modeling):** ë¶ˆì•ˆì •í•œ ì—­ì§„ì ì‹œìŠ¤í…œì´ MuJoCo ë¬¼ë¦¬ ì—”ì§„ì—ì„œ ì–´ë–»ê²Œ êµ¬í˜„ë˜ëŠ”ì§€ ì´í•´í•©ë‹ˆë‹¤.
2. **ìƒíƒœ ê´€ì¸¡ (State Observation):** ì œì–´ë¥¼ ìœ„í•´ ì‹œìŠ¤í…œì˜ ìƒíƒœ(State)ë¥¼ ì •ì˜í•˜ê³  ê´€ì¸¡í•˜ëŠ” ë°©ë²•ì„ ìµí™ë‹ˆë‹¤.
3. **ê°•í™”í•™ìŠµ í™˜ê²½ êµ¬ì¶• (RL Environment):** ë¬¼ë¦¬ ì—”ì§„ì„ AI í•™ìŠµì„ ìœ„í•œ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤(Gymnasium)ë¡œ ë˜í•‘(Wrapping)í•©ë‹ˆë‹¤.
4. **ë³´ìƒ í•¨ìˆ˜ ì„¤ê³„ (Reward Shaping):** ì œì–´ ëª©í‘œ(ê· í˜• ìœ ì§€)ë¥¼ ìˆ˜í•™ì ì¸ ë³´ìƒ í•¨ìˆ˜ë¡œ ë³€í™˜í•˜ê³  PPO ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.

> **Pre-requisites:** `stable-baselines3`ì™€ `gymnasium` ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì¹˜ê°€ ì•ˆ ë˜ì–´ ìˆë‹¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”. `pip install gymnasium stable-baselines3`

### 1. Cart-Pole ì‹œìŠ¤í…œì˜ ë¬¼ë¦¬í•™ê³¼ MuJoCo ëª¨ë¸ë§

#### 1.1 ì—­ì§„ì(Inverted Pendulum)ë€?

ì¼ë°˜ì ì¸ ì§„ìëŠ” ì¤‘ë ¥ì— ì˜í•´ ì•„ë˜ë¡œ ì¶• ì²˜ì ¸ ì•ˆì •ëœ ìƒíƒœë¥¼ ìœ ì§€í•˜ë ¤ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ **ì—­ì§„ì**ëŠ” ë§‰ëŒ€(Pole)ê°€ ìœ„ë¥¼ í–¥í•´ ì„œ ìˆëŠ” ìƒíƒœë¡œ, ì¤‘ë ¥ì— ì˜í•´ ëŠì„ì—†ì´ ì“°ëŸ¬ì§€ë ¤ í•˜ëŠ” **ë³¸ì§ˆì ìœ¼ë¡œ ë¶ˆì•ˆì •í•œ(Unstable)** ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

ìš°ë¦¬ëŠ” ë§‰ëŒ€ë¥¼ ì§ì ‘ ì¡ì„ ìˆ˜ ì—†ê³ , ë§‰ëŒ€ê°€ ì—°ê²°ëœ ì¹´íŠ¸(Cart)ë¥¼ ì¢Œìš°ë¡œ ë°€ì–´ì„œ ê·¸ ê´€ì„±ë ¥ìœ¼ë¡œ ë§‰ëŒ€ì˜ ê· í˜•ì„ ì¡ì•„ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ **ê³¼ì†Œêµ¬ë™(Underactuated) ì‹œìŠ¤í…œ**ì´ë¼ê³  í•©ë‹ˆë‹¤. (ì œì–´ ì…ë ¥ì€ 1ê°œì¸ë°, ì œì–´í•´ì•¼ í•  ììœ ë„ëŠ” ì¹´íŠ¸ ìœ„ì¹˜ì™€ ë§‰ëŒ€ ê°ë„ 2ê°œì„)

#### 1.2 í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬

```python
import os
os.environ['MUJOCO_GL'] = 'egl'   # mujoco import ì „ì—!
 
import mujoco
import numpy as np
import mediapy as media
import matplotlib.pyplot as plt
```

#### 1.2 MuJoCo XML ì •ì˜

MuJoCoì—ì„œëŠ” ì´ ë¬¼ë¦¬ ì‹œìŠ¤í…œì„ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•©ë‹ˆë‹¤.

* **Slide Joint:** ì¹´íŠ¸ê°€ ë ˆì¼ ìœ„ì—ì„œ ì§ì„ ìš´ë™ì„ í•˜ë„ë¡ êµ¬ì†í•©ë‹ˆë‹¤.
* **Hinge Joint:** ë§‰ëŒ€ê°€ ì¹´íŠ¸ ìœ„ì—ì„œ íšŒì „ìš´ë™ì„ í•˜ë„ë¡ êµ¬ì†í•©ë‹ˆë‹¤.
* **Actuator (Motor):** ìŠ¬ë¼ì´ë“œ ì¡°ì¸íŠ¸(ì¹´íŠ¸)ì—ë§Œ í˜(Force)ì„ ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
xml = """
<mujoco model="inverted pendulum">
    <compiler inertiafromgeom="true"/>
    <default>
        <joint armature="0" damping="1" limited="true"/>
        <geom friction="1 0.1 0.1" rgba="0.7 0.7 0 1"/>
        <tendon/>
        <motor ctrlrange="-3 3"/>
    </default>
    <option gravity="0 0 -9.81" integrator="Euler" timestep="0.01"/>
    <size nstack="3000"/>
    <worldbody>
        <!-- ë ˆì¼ (ë°”ë‹¥) -->
        <geom name="rail" pos="0 0 0" quat="0.707 0 0.707 0" rgba="0.3 0.3 0.7 1"
              size="0.02 1" type="capsule" contype="0" conaffinity="0"/>
        
        <!-- ì›€ì§ì´ëŠ” ì¹´íŠ¸ (Cart) -->
        <body name="cart" pos="0 0 0">
            <!-- ìŠ¬ë¼ì´ë“œ ì¡°ì¸íŠ¸: ì§ì„  ìš´ë™ -->
            <joint axis="1 0 0" limited="true" name="slider" pos="0 0 0"
                   range="-1.2 1.2" type="slide"/>
            <geom name="cart" pos="0 0 0" quat="0.707 0 0.707 0"
                  size="0.1 0.1" type="capsule"/>
            
            <!-- ì¹´íŠ¸ ìœ„ì˜ ë§‰ëŒ€ (Pole) -->
            <body name="pole" pos="0 0 0">
                <!-- íŒì§€ ì¡°ì¸íŠ¸: íšŒì „ ìš´ë™ -->
                <joint axis="0 1 0" name="hinge" pos="0 0 0"
                       type="hinge" limited="false"/>
                <geom fromto="0 0 0 0.001 0 0.6" name="cpole"
                      rgba="0 0.7 0.7 1" size="0.049 0.3" type="capsule"/>
            </body>
        </body>
    </worldbody>
    <!-- ì•¡ì¶”ì—ì´í„°: ì¹´íŠ¸ë¥¼ ë¯¸ëŠ” ëª¨í„° -->
    <actuator>
        <motor ctrllimited="true" ctrlrange="-3 3" gear="10"
               joint="slider" name="slide"/>
    </actuator>
</mujoco>
"""
```

### 2. ìƒíƒœ(State)ì˜ ì •ì˜ì™€ ê´€ì¸¡

ì œì–´ë¥¼ í•˜ê¸° ìœ„í•´ì„œëŠ” í˜„ì¬ ì‹œìŠ¤í…œì´ ì–´ë–¤ ìƒí™©ì¸ì§€ ì •í™•íˆ ì•Œì•„ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìƒíƒœ(State)ë¼ê³  í•©ë‹ˆë‹¤. ì—­ì§„ì ì‹œìŠ¤í…œì˜ ìƒíƒœ $$x$$ëŠ” ë‹¤ìŒ 4ê°€ì§€ ìš”ì†Œë¡œ ì •ì˜ë©ë‹ˆë‹¤.

$$
\text{State } x = [p, \theta, \dot{p}, \dot{\theta}]^T
$$

1. $$p$$ : ì¹´íŠ¸ ìœ„ì¹˜ (Cart Position) - ë ˆì¼ ì¤‘ì‹¬ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ê°€?
2. $$\theta$$: ë§‰ëŒ€ì˜ ê°ë„ (Pole Angle) - ìˆ˜ì§ì—ì„œ ì–¼ë§ˆë‚˜ ê¸°ìš¸ì–´ì¡ŒëŠ”ê°€?
3. $$\dot{p}$$: ì¹´íŠ¸ì˜ ì†ë„ (Cart Velocity) - ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ ì´ë™ ì¤‘ì¸ê°€?
4. $$\dot{\theta}$$: ë§‰ëŒ€ì˜ ê°ì†ë„ (Pole Angular Velocity) - ì–¼ë§ˆë‚˜ ë¹ ë¥´ê²Œ ì“°ëŸ¬ì§€ê³  ìˆëŠ”ê°€?

MuJoCoëŠ” `data.qpos`(ìœ„ì¹˜)ì™€ `data.qvel`(ì†ë„)ë¥¼ í†µí•´ ì´ ê°’ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.

```python
def create_env():
    """MuJoCo ëª¨ë¸/ë°ì´í„°/ë Œë”ëŸ¬ ìƒì„±."""
    model = mujoco.MjModel.from_xml_string(xml)
    data = mujoco.MjData(model)
    renderer = mujoco.Renderer(model, height=480, width=640)
    return model, data, renderer


def reset_state(data, q_init=None, qv_init=None):
    """qpos, qvel ì´ˆê¸°í™”. q_init, qv_initì€ ë¦¬ìŠ¤íŠ¸ë‚˜ np.arrayë¡œ ì „ë‹¬."""
    mujoco.mj_resetData(data.model, data)
    if q_init is not None:
        data.qpos[:len(q_init)] = q_init
    if qv_init is not None:
        data.qvel[:len(qv_init)] = qv_init
    mujoco.mj_forward(data.model, data)


def get_state(data):
    """
    ìƒíƒœ ë²¡í„° [x_cart, theta_pole, x_dot, theta_dot] ë°˜í™˜.
    qpos[0] : slider joint (cart position)
    qpos[1] : hinge joint (pole angle)
    """
    x = float(data.qpos[0])
    theta = float(data.qpos[1])
    x_dot = float(data.qvel[0])
    theta_dot = float(data.qvel[1])
    return np.array([x, theta, x_dot, theta_dot])


def rollout(model, data, renderer,
            duration=10.0, framerate=60,
            ctrl_func=None,
            q_init=None, qv_init=None):
    """
    í•œ ì—í”¼ì†Œë“œ ì‹œë®¬ë ˆì´ì…˜:
      - ctrl_func(state, t)ë¡œ ì œì–´ ì…ë ¥ ìƒì„± (Noneì´ë©´ 0 ì…ë ¥)
      - ìƒíƒœ ê¶¤ì ê³¼ í”„ë ˆì„ ê¸°ë¡.

    ë°˜í™˜:
      times, states, controls, frames
    """
    reset_state(data, q_init=q_init, qv_init=qv_init)

    dt = model.opt.timestep
    times = []
    states = []
    controls = []
    frames = []

    # ë©”ì¸ ë£¨í”„
    while data.time < duration:
        t = float(data.time)
        state = get_state(data)

        # ì œì–´ ì…ë ¥ ê³„ì‚°
        if ctrl_func is None:
            u = 0.0
        else:
            u = float(ctrl_func(state, t))

        # ctrl ì ìš©
        data.ctrl[0] = u

        # í•œ ìŠ¤í… ì§„í–‰
        mujoco.mj_step(model, data)

        # ë¡œê¹…
        times.append(t)
        states.append(state)
        controls.append(u)

        # í”„ë ˆì„ ìƒ˜í”Œë§ (ëŒ€ëµ framerateì— ë§ì¶”ê¸°)
        if len(frames) < data.time * framerate:
            renderer.update_scene(data)
            pixels = renderer.render()
            frames.append(pixels)

    return (
        np.array(times),
        np.vstack(states),   # shape: [T, 4]
        np.array(controls),  # shape: [T]
        np.array(frames)     # shape: [N_frames, H, W, 3]
    )

def plot_states(times, states, controls=None, title="Cart-Pole States"):
    """
    states: shape [T, 4] = [x, theta, x_dot, theta_dot]
    controls: shape [T] or None
    """
    x = states[:, 0]
    theta = states[:, 1]
    x_dot = states[:, 2]
    theta_dot = states[:, 3]

    if controls is None:
        fig, axs = plt.subplots(2, 2, figsize=(12, 8))
        fig.suptitle(title, fontsize=16)

        axs[0, 0].plot(times, x, label="Cart Position [m]")
        axs[0, 0].set_ylabel("Position [m]")
        axs[0, 0].set_title("Cart Position")
        axs[0, 0].grid(True)
        axs[0, 0].legend()

        axs[0, 1].plot(times, x_dot, "r", label="Cart Velocity [m/s]")
        axs[0, 1].set_ylabel("Velocity [m/s]")
        axs[0, 1].set_title("Cart Velocity")
        axs[0, 1].grid(True)
        axs[0, 1].legend()

        axs[1, 0].plot(times, theta, "g", label="Pole Angle [rad]")
        axs[1, 0].set_ylabel("Angle [rad]")
        axs[1, 0].set_title("Pole Angle")
        axs[1, 0].set_xlabel("Time [s]")
        axs[1, 0].grid(True)
        axs[1, 0].legend()

        axs[1, 1].plot(times, theta_dot, "m", label="Pole Angular Velocity [rad/s]")
        axs[1, 1].set_ylabel("Angular Velocity [rad/s]")
        axs[1, 1].set_title("Pole Angular Velocity")
        axs[1, 1].set_xlabel("Time [s]")
        axs[1, 1].grid(True)
        axs[1, 1].legend()

        plt.tight_layout(rect=[0, 0, 1, 0.96])
        plt.show()

    else:
        fig, axs = plt.subplots(3, 1, figsize=(10, 8), sharex=True)
        fig.suptitle(title, fontsize=16)

        axs[0].plot(times, x, label="Cart Position [m]")
        axs[0].plot(times, theta, label="Pole Angle [rad]")
        axs[0].set_ylabel("Pos / Angle")
        axs[0].grid(True)
        axs[0].legend()

        axs[1].plot(times, x_dot, label="Cart Velocity [m/s]")
        axs[1].plot(times, theta_dot, label="Pole Angular Velocity [rad/s]")
        axs[1].set_ylabel("Vel / Ang. Vel")
        axs[1].grid(True)
        axs[1].legend()

        axs[2].plot(times, controls, "r", label="Control Input [N]")
        axs[2].set_xlabel("Time [s]")
        axs[2].set_ylabel("Force [N]")
        axs[2].grid(True)
        axs[2].legend()

        plt.tight_layout(rect=[0, 0, 1, 0.96])
        plt.show()
```

#### 2.1 ì œì–´ ì—†ëŠ” ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜

ë¨¼ì € ì œì–´ê¸° ì—†ì´ ë§‰ëŒ€ë¥¼ ì‚´ì§ ê¸°ìš¸ì˜€ì„ ë•Œ ì–´ë–¤ ì¼ì´ ì¼ì–´ë‚˜ëŠ”ì§€ ê´€ì°°í•´ ë´…ì‹œë‹¤. ë‹¹ì—°íˆ ë§‰ëŒ€ëŠ” ì¤‘ë ¥ì— ì˜í•´ ì“°ëŸ¬ì§€ê³ , ë©ˆì¶° ìˆë˜ ì¹´íŠ¸ë„ ë°˜ì‘ìš©ìœ¼ë¡œ ì•½ê°„ ì›€ì§ì´ê²Œ ë©ë‹ˆë‹¤.

```python
model, data, renderer = create_env()

# ì´ˆê¸° ìƒíƒœ: í´ì„ ì‚´ì§(0.1 rad) ê¸°ìš¸ì¸ ìƒíƒœì—ì„œ ì‹œì‘
q_init = [0.0, 0.1]  # [x, theta]
qv_init = [0.0, 0.0]   # [x_dot, theta_dot]

duration = 10.0
framerate = 60

times, states, controls, frames = rollout(
    model, data, renderer,
    duration=duration,
    framerate=framerate,
    ctrl_func=None,     # ë¬´ì œì–´
    q_init=q_init,
    qv_init=qv_init,
)

print("Simulation finished. Plotting states...")
plot_states(times, states, controls=None, title="Free Cart-Pole Dynamics")
```

<figure><img src="../.gitbook/assets/image (7).png" alt=""><figcaption></figcaption></figure>

### 3. Gymnasium í™˜ê²½ êµ¬ì¶• ë° ë³´ìƒ ì„¤ê³„

<figure><img src="../.gitbook/assets/image (8).png" alt=""><figcaption></figcaption></figure>

ìš°ë¦¬ëŠ” LQR ê°™ì€ ìˆ˜ì¹˜ í•´ì„ì  ë°©ë²• ëŒ€ì‹ , ê°•í™”í•™ìŠµì„ ì‚¬ìš©í•´ ì œì–´ê¸°ë¥¼ ë§Œë“¤ ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ MuJoCoë¥¼ Gymnasium Environmentë¡œ í¬ì¥í•´ì•¼ í•©ë‹ˆë‹¤.

#### 3.1 ë³´ìƒ í•¨ìˆ˜(Reward Function) ì„¤ê³„ì˜ í•µì‹¬

ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸ëŠ” **ë³´ìƒ(Reward)ì„ ìµœëŒ€í™”**í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ í–‰ë™ì„ í•™ìŠµí•©ë‹ˆë‹¤. ë”°ë¼ì„œ "ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì´ìƒì ì¸ ì›€ì§ì„"ì„ ìˆ˜í•™ì ìœ¼ë¡œ ì •ì˜í•´ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤.&#x20;

ìš°ë¦¬ì˜ ëª©í‘œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

1. **Pole Angle**  $$(\theta \approx 0)$$ **:** ë§‰ëŒ€ë¥¼ ë˜‘ë°”ë¡œ ì„¸ì›Œë¼. (ê°€ì¥ ì¤‘ìš”)
2. **Cart Position** $$(p \approx 0)$$**:** ì¹´íŠ¸ë¥¼ ì¤‘ì•™ì— ìœ„ì¹˜ì‹œì¼œë¼. (ë ˆì¼ ë°–ìœ¼ë¡œ ë‚˜ê°€ì§€ ì•Šê²Œ)
3. **Control Input** $$(u \approx 0)$$ í˜ì„ ì ê²Œ ì¨ë¼. (ì—ë„ˆì§€ íš¨ìœ¨ì„± ë° ë¶€ë“œëŸ¬ìš´ ì›€ì§ì„)

ì´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ë¹„ìš© í•¨ìˆ˜(Cost Function)ê°€ ë˜ë©°, ë³´ìƒì€ `1.0 - Cost` í˜•íƒœë¡œ ì •ì˜í•˜ì—¬ ë¹„ìš©ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ê²Œ í•©ë‹ˆë‹¤.

$$\text{Cost} = w_1 \theta^2 + w_2 p^2 + w_3 \dot{p}^2 + w_4 \dot{\theta}^2 + w_5 u^2$$

```python
import gymnasium as gym
from gymnasium import spaces
from stable_baselines3 import PPO

class CartPoleMuJoCoEnv(gym.Env):
    metadata = {"render_modes": ["rgb_array"], "render_fps": 60}

    def __init__(self, render_mode=None):
        super().__init__()
        # ê¸°ì¡´ ìœ í‹¸ ì¬ì‚¬ìš©
        self.model, self.data, self.renderer = create_env()
        self.dt = self.model.opt.timestep

        # ê´€ì¸¡ ê³µê°„: [x, theta, x_dot, theta_dot]
        high = np.array([np.inf, np.inf, np.inf, np.inf], dtype=np.float32)
        self.observation_space = spaces.Box(-high, high, dtype=np.float32)

        # í–‰ë™ ê³µê°„: ì¹´íŠ¸ì— ê°€í•˜ëŠ” í˜ (ì—°ì†, -3 ~ 3)
        self.action_space = spaces.Box(
            low=np.array([-3.0], dtype=np.float32),
            high=np.array([3.0], dtype=np.float32),
            dtype=np.float32,
        )

        self.render_mode = render_mode
        self.max_steps = int(10.0 / self.dt)  # ì—í”¼ì†Œë“œ ìµœëŒ€ ê¸¸ì´ (ëŒ€ëµ 10ì´ˆ)
        self.step_count = 0

    def _get_obs(self):
        return get_state(self.data).astype(np.float32)

    def _get_info(self):
        return {}

    def reset(self, *, seed=None, options=None):
        super().reset(seed=seed)
        self.step_count = 0

        # ì´ˆê¸°í™” ì‹œ ëœë¤í•˜ê²Œ ì•½ê°„ ê¸°ìš¸ì–´ì§€ê²Œ í•¨ (-0.15 ~ 0.15 rad)
        theta0 = self.np_random.uniform(-0.15, 0.15)
        q_init = [0.0, theta0]
        qv_init = [0.0, 0.0]
        reset_state(self.data, q_init=q_init, qv_init=qv_init)

        obs = self._get_obs()
        info = self._get_info()
        return obs, info

    def step(self, action):
        self.step_count += 1

        # actionì€ shape (1,) ì´ë¼ê³  ê°€ì •
        u = float(np.clip(action[0], -3.0, 3.0))
        self.data.ctrl[0] = u

        # í•œ ìŠ¤í… ì§„í–‰
        mujoco.mj_step(self.model, self.data)

        obs = self._get_obs()
        x, theta, x_dot, theta_dot = obs

        # ë³´ìƒ ì„¤ê³„ (Reward Shaping)
        # í´ì´ ì„¸ì›Œì ¸ ìˆê³  ì¹´íŠ¸ê°€ ê°€ìš´ë°ì— ìˆì„ìˆ˜ë¡ ë³´ìƒ ë†’ê²Œ
        cost = (
            1.0 * theta**2 +        # ê°ë„ ì œê³± (ê¸°ìš¸ì–´ì§ˆìˆ˜ë¡ í˜ë„í‹°)
            0.1 * x**2 +            # ìœ„ì¹˜ ì œê³± (ì¤‘ì•™ì—ì„œ ë©€ì–´ì§ˆìˆ˜ë¡ í˜ë„í‹°)
            0.01 * x_dot**2 +       # ì†ë„ ì œê³± (ë„ˆë¬´ ë¹¨ë¦¬ ì›€ì§ì´ë©´ í˜ë„í‹°)
            0.01 * theta_dot**2 +
            0.001 * u**2            # ì œì–´ ì…ë ¥ ì œê³± (í˜ì„ ë§ì´ ì“°ë©´ í˜ë„í‹°)
        )
        reward = 1.0 - cost  # ìµœëŒ€ 1 ê·¼ì²˜, ìƒíƒœê°€ ë‚˜ì ìˆ˜ë¡ ì‘ì•„ì§

        # ì¢…ë£Œ ì¡°ê±´
        terminated = bool(
            abs(theta) > np.pi / 2.0 or  # í´ì´ 90ë„ ì´ìƒ ê¸°ìš¸ì–´ì§€ë©´ ì‹¤íŒ¨
            abs(x) > 1.2                 # ë ˆì¼ ë°–ìœ¼ë¡œ ë‚˜ê°€ë©´ ì¢…ë£Œ
        )
        truncated = bool(self.step_count >= self.max_steps)

        info = self._get_info()
        return obs, reward, terminated, truncated, info

    def render(self):
        # PPO í•™ìŠµ ì¤‘ì—ëŠ” í˜¸ì¶œ ì•ˆ í•´ë„ ë˜ê³ ,
        # ë‚˜ì¤‘ì— í‰ê°€í•  ë•Œ rgb_arrayë¡œ í”„ë ˆì„ ë½‘ëŠ” ë° ì”€
        self.renderer.update_scene(self.data)
        img = self.renderer.render()
        return img

    def close(self):
        pass
```

### 4. PPO ê°•í™”í•™ìŠµ ë° ì œì–´ ì„±ëŠ¥ ê²€ì¦

ì´ì œ **PPO (Proximal Policy Optimization)** ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ ì œì–´ ì •ì±…(Policy)ì„ í•™ìŠµí•©ë‹ˆë‹¤. PPOëŠ” í˜„ì¬ ìƒíƒœ _**s**_&#xB97C; ì…ë ¥ë°›ì•„ ìµœì ì˜ í˜ _**u**_&#xB97C; ì¶œë ¥í•˜ëŠ” ì‹ ê²½ë§ì„ í•™ìŠµí•©ë‹ˆë‹¤.

$$
u = \pi_\phi(s)
$$

#### 4.1 í•™ìŠµ ì§„í–‰ (Training)

```python
# Gymnasium env ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
env = CartPoleMuJoCoEnv()

# MlpPolicy: ê´€ì¸¡ â†’ MLP â†’ ì—°ì† í–‰ë™
model = PPO(
    "MlpPolicy",
    env,
    verbose=1,
    learning_rate=3e-4,
    n_steps=1024,
    batch_size=64,
    gamma=0.99,
)

# í•™ìŠµ ìŠ¤í… ìˆ˜ëŠ” ìƒí™© ë´ê°€ë©´ì„œ ëŠ˜ë ¤ë„ ë¨ (ì˜ˆ: 100_000 ~ 300_000)
model.learn(total_timesteps=150_000)

# í•™ìŠµëœ ëª¨ë¸ ì €ì¥
model.save("ppo_cartpole_mujoco")
```

#### 4.2 ì œì–´ ê²°ê³¼ í™•ì¸ (Evaluation)

í•™ìŠµëœ ëª¨ë¸ì´ ì‹¤ì œë¡œ ë§‰ëŒ€ë¥¼ ì„¸ìš¸ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

* **ì„±ê³µì ì¸ ì œì–´ì˜ ê¸°ì¤€:**
  * **Pole Angle ê·¸ë˜í”„:** 0ë„ ê·¼ì²˜ì—ì„œ ë¯¸ì„¸í•˜ê²Œ ì§„ë™í•˜ë©° ìœ ì§€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
  * **Cart Position ê·¸ë˜í”„:** ì¤‘ì•™(0) ê·¼ì²˜ì— ë¨¸ë¬¼ëŸ¬ì•¼ í•©ë‹ˆë‹¤.
  * **Action ê·¸ë˜í”„:** ë§‰ëŒ€ê°€ ì“°ëŸ¬ì§€ë ¤ í•  ë•Œë§ˆë‹¤ ì ì ˆí•œ í˜ì´ ê°€í•´ì§€ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

```python
eval_env = CartPoleMuJoCoEnv()
obs, info = eval_env.reset()

duration = 10.0
framerate = 60
max_steps = int(duration / eval_env.dt)

frames = []
times = []
states = []
controls = []

print("Running Evaluation Episode...")
for step in range(max_steps):
    # í•™ìŠµëœ ì •ì±…(AI)ì—ê²Œ í˜„ì¬ ìƒíƒœë¥¼ ë³´ì—¬ì£¼ê³  í–‰ë™(Action)ì„ ê²°ì •í•˜ê²Œ í•¨
    # deterministic=True: í™•ë¥ ì  íƒìƒ‰ì„ ë„ê³  ê°€ì¥ ì¢‹ì€ í–‰ë™ë§Œ ì„ íƒ
    action, _ = model.predict(obs, deterministic=True)

    # í™˜ê²½ì— í–‰ë™ ì ìš©
    obs, reward, terminated, truncated, info = eval_env.step(action)

    # ê¸°ë¡
    state = get_state(eval_env.data)
    states.append(state)
    controls.append(float(action[0]))
    times.append(eval_env.data.time)

    # ì˜ìƒ í”„ë ˆì„ ì €ì¥
    frame = eval_env.render()
    frames.append(frame)

    if terminated or truncated:
        print(f"Episode ended at step {step}")
        break

states = np.vstack(states)
controls = np.array(controls)
times = np.array(times)

print("Evaluation finished. Plotting states...")
plot_states(times, states, controls=controls, title="PPO-Controlled Cart-Pole")
```

```python
print("Rendering PPO policy video with mediapy...")
media.show_video(frames, fps=framerate)
```

#### ğŸ“ˆ ê²°ê³¼ ë¶„ì„

<figure><img src="../.gitbook/assets/image (6).png" alt=""><figcaption></figcaption></figure>

ê·¸ë˜í”„ë¥¼ ë³´ë©´ ì´ˆê¸°ì—ëŠ” ë§‰ëŒ€ê°€ ê¸°ìš¸ì–´ì ¸ ìˆì–´($$\theta \neq 0$$) ì¹´íŠ¸ê°€ ê°•í•˜ê²Œ ì›€ì§ì´ë©°(u ë°œìƒ) ì¤‘ì‹¬ì„ ì¡ìœ¼ë ¤ ë…¸ë ¥í•©ë‹ˆë‹¤. ì‹œê°„ì´ ì§€ë‚˜ë©´ ë§‰ëŒ€ëŠ” ìˆ˜ì§ ìƒíƒœë¡œ ìˆ˜ë ´í•˜ê³ , ì¹´íŠ¸ë„ ì¤‘ì•™ìœ¼ë¡œ ëŒì•„ì˜¤ë©° ì œì–´ ì…ë ¥(u)ì´ 0ì— ê°€ê¹Œì›Œì§€ëŠ” **ì•ˆì •í™”(Stabilization)** ìƒíƒœì— ë„ë‹¬í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ ê°•í™”í•™ìŠµì„ í†µí•´ ì–»ì€ ì œì–´ê¸°ì˜ ì„±ëŠ¥ì…ë‹ˆë‹¤.

#### ğŸ“ í•™ìƒìš© ê³¼ì œ: Cart-Pole MuJoCo í™˜ê²½ ë¶„ì„ ë³´ê³ ì„œ

ì‹¤ìŠµ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ê°•í™”í•™ìŠµì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œë“¤ì´ ì½”ë“œìƒì—ì„œ ì–´ë–»ê²Œ ì •ì˜ë˜ì–´ ìˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•˜ì‹œì˜¤.

1\. State (ìƒíƒœ, Observation)

* ì—ì´ì „íŠ¸(AI)ê°€ ë§¤ ìˆœê°„ ê´€ì¸¡í•˜ëŠ” ì •ë³´ëŠ” ë¬´ì—‡ì¸ê°€?
* ë°ì´í„°ì˜ ì°¨ì›(Dimension)ì€ ëª‡ì´ë©°, ê°ê°ì˜ ê°’ì€ ë¬¼ë¦¬ì ìœ¼ë¡œ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ê°€?

2\. Action (í–‰ë™)

* ì—ì´ì „íŠ¸ê°€ í™˜ê²½ì— ê°€í•  ìˆ˜ ìˆëŠ” í–‰ë™ì€ ë¬´ì—‡ì¸ê°€?
* ì´ í–‰ë™ì€ ì´ì‚°ì (Discrete)ì¸ê°€, ì—°ì†ì (Continuous)ì¸ê°€?
* í–‰ë™ ê°’ì˜ ë²”ìœ„(Range)ëŠ” ì–´ë–»ê²Œ ë˜ëŠ”ê°€?

3\. Reward Function (ë³´ìƒ í•¨ìˆ˜)

* ì—ì´ì „íŠ¸ê°€ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ê¸° ìœ„í•œ ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€? (ëª©í‘œ)
* ë°˜ëŒ€ë¡œ ì ìˆ˜ê°€ ê¹ì´ëŠ”(Penalty) ìš”ì¸ 4ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€? ì½”ë“œì˜ `cost` ìˆ˜ì‹ì„ ë³´ê³  í•´ì„í•˜ì‹œì˜¤.

4\. Termination (ì¢…ë£Œ ì¡°ê±´)

* ì—í”¼ì†Œë“œê°€ "ì‹¤íŒ¨"ë¡œ ê°„ì£¼ë˜ì–´ ì¦‰ì‹œ ì¢…ë£Œë˜ëŠ” ì¡°ê±´ 2ê°€ì§€ëŠ” ë¬´ì—‡ì¸ê°€?

5\. Algorithm (ì•Œê³ ë¦¬ì¦˜)

* ì‚¬ìš©ëœ ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì˜ ì´ë¦„ì€ ë¬´ì—‡ì´ë©°, ì–´ë–¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í–ˆëŠ”ê°€?

